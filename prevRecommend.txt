import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import argparse
import re

def preprocess_input(user_input):
    """Preprocess user input by removing common stop words and extracting names."""
    stop_words = {'i', 'like', 'want', 'prefer', 'looking for'}
    words = user_input.lower().split()
    filtered_words = [word for word in words if word not in stop_words]
    return ' '.join(filtered_words)

def extract_names(user_input):
    """Extract potential names from user input using regex (assumes capitalized words)."""
    name_pattern = re.compile(r'\b[A-Z][a-z]+\s[A-Z][a-z]+\b')
    return name_pattern.findall(user_input)

def load_dataset(filepath):
    """Load the Netflix dataset from a CSV file."""
    df = pd.read_csv(filepath)
    df = df[['title', 'description', 'listed_in', 'rating', 'director', 'cast']].fillna('')  # Handle missing values
    
    # Boost metadata importance by repeating key features
    df['combined_text'] = (
        df['description'] + ' ' + (df['listed_in'] + ' ') * 2 +
        (df['rating'] + ' ') * 3 + (df['director'] + ' ') + (df['cast'] + ' ')
    )
    
    return df

def filter_by_exact_names(data, names):
    """Filter dataset for exact name matches in cast or director fields."""
    if not names:
        return data  # No filtering needed if no names are provided
    
    mask = data.apply(lambda row: any(name in row['cast'] or name in row['director'] for name in names), axis=1)
    filtered_data = data[mask]
    
    return filtered_data if not filtered_data.empty else data  # Default to full dataset if no match

def compute_similarity(data, user_input, top_n=10):
    """Compute text similarity using TF-IDF and return top N recommendations."""
    vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1,3), min_df=1, max_features=8000)
    tfidf_matrix = vectorizer.fit_transform(data['combined_text'])
    
    user_input = preprocess_input(user_input)
    user_tfidf = vectorizer.transform([user_input])
    
    similarity_scores = cosine_similarity(user_tfidf, tfidf_matrix).flatten()
    top_indices = np.argsort(similarity_scores)[-top_n:][::-1]
    
    recommendations = data.iloc[top_indices]
    scores = similarity_scores[top_indices] / similarity_scores.max()  # Normalize scores
    return recommendations, scores

def main(user_input, filepath):
    """Main function to load dataset, compute recommendations, and display results."""
    data = load_dataset(filepath)
    names = extract_names(user_input)
    filtered_data = filter_by_exact_names(data, names)
    recommendations, scores = compute_similarity(filtered_data, user_input)
    
    print("Top recommendations:")
    for i, (title, score) in enumerate(zip(recommendations['title'], scores)):
        print(f"{i+1}. {title} (Score: {score:.4f})")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("user_input", type=str, help="User's preference description")
    parser.add_argument("filepath", type=str, help="Path to Netflix dataset CSV file")
    args = parser.parse_args()
    main(args.user_input, args.filepath)
